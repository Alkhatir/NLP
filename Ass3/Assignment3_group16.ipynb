{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUGhn9rVgDN0"
      },
      "source": [
        "Please fill out the information of your group!\n",
        "\n",
        "| <p style=\"text-align: center;\">First Name</p>  | <p style=\"text-align: center;\">Family Name</p> | Matr.-No. |\n",
        "| ---------------------------------------------- | ---------------------------------------------- | -------- |\n",
        "| <p style=\"text-align: left\">ISSA</p>| <p style=\"text-align: left\">Sayegh</p> | k11904028 |\n",
        "| <p style=\"text-align: left\">PEER</p>| <p style=\"text-align: left\">HANNA</p> | k12220447 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kF9OyBVgDN1"
      },
      "source": [
        "<h2 style=\"text-align: center\">344.075 KV: Natural Language Processing (WS2024)</h2>\n",
        "<h1 style=\"color:rgb(0,120,170)\">Assignment 3</h1>\n",
        "<h2 style=\"color:rgb(0,120,170)\">Document Classification with PyTorch and BERT</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0GjAsc6gDN2"
      },
      "source": [
        "<b>Terms of Use</b><br>\n",
        "This  material is prepared for educational purposes at the Johannes Kepler University (JKU) Linz, and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
        "\n",
        "\n",
        "**Authors:** Shah Nawaz, Shahed Masoudian<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYpU7gmrgDN2"
      },
      "source": [
        "<h2>Table of contents</h2>\n",
        "<ol>\n",
        "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
        "    <a href=\"#section-tensorboard\"><li style=\"font-size:large;font-weight:bold\">Bonus Task: Logging and Publishing Experiment Results (2 extra point)</li></a>\n",
        "    <a href=\"#section-taskA\"><li style=\"font-size:large;font-weight:bold\">Task A: Document Classification with PyTorch (25 points)</li></a>\n",
        "    <a href=\"#section-taskB\"><li style=\"font-size:large;font-weight:bold\">Task B: Document Classification with BERT (15 points)</li></a>\n",
        "    \n",
        "    \n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXUl6OC5gDN2"
      },
      "source": [
        "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DooM2JwLgDN2"
      },
      "source": [
        "### Assignment objective\n",
        "This assignment aims to provide the necessary practices for learning the principles of deep learning programing in NLP using PyTorch. To this end, Task A provides the space for becoming fully familiar with PyTorch programming by implementing a \"simple\" document (sentence) classification model with PyTorch, and Task B extends this classifier with a BERT model. As the assignment requires working with PyTorch and Huggingface Transformers, please familiarize yourself with these libraries using any possible available teaching resources in particular the libraries' documentations. The assignment has in total **40 points**, and also offers **2 extra points** which can cover any missing point.\n",
        "\n",
        "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way!\n",
        "\n",
        "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYPlvPe9gDN2"
      },
      "source": [
        "### Libraries & Dataset\n",
        "\n",
        "The assignment should be implemented with recent versions of `Python`, `PyTorch` and, `transformers`. Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
        "\n",
        "To conduct the experiments, we use a subset of the `HumSet` dataset [1] (https://blog.thedeep.io/humset/). `HumSet` is created by the DEEP (https://www.thedeep.io) project â€“ an open source platform which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset contains the classes (labels) referring to the humanitarian sectors like agriculture, health, and protection. The dataset contains an overall number of 17,301 data points.\n",
        "\n",
        "Download the dataset from the Moodle page of the course.\n",
        "\n",
        "the provided zip file consists of the following files:\n",
        "- `thedeep.subset.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
        "- `thedeep.subset.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
        "- `thedeep.subset.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
        "- `thedeep.subset.label.txt`: Captions of the labels.\n",
        "- `thedeep.ToU.txt`: Terms of use of the dataset.\n",
        "\n",
        "[1] HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response\n",
        "*Selim Fekih, Nicolo' Tamagnone, Benjamin Minixhofer, Ranjan Shrestha, Ximena Contla, Ewan Oglethorpe and Navid Rekabsaz.*\n",
        "In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP), December 2022.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpCnTCqtgDN3"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Each group should submit the following two files:\n",
        "\n",
        "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook.\n",
        "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
        "\n",
        "You do not need to include the data files in the submission.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYcHFkyJgDN3"
      },
      "source": [
        "<a name=\"section-tensorboard\"></a><h2 style=\"color:rgb(0,120,170)\">Bonus Task: Logging and Publishing Experiment Results (2 extra point)</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwoCxabhgDN3"
      },
      "source": [
        "In all experiments of this assignment, use any experiment monitoring tool like [`TensorBoard`](https://www.tensorflow.org/tensorboard), [`wandb`](https://wandb.ai) to log and store all useful information about the training and evaluation of the models. Feel free to log any important aspect in particular the changes in evaluation results on validation, in training loss, and in learning rate.\n",
        "\n",
        "After finalizing all experiments and cleaning any unnecessary experiment, **provide the URL to the results monitoring page below**.\n",
        "\n",
        "For instance if using [`TensorBoard.dev`](https://tensorboard.dev), you can run the following command in the folder of log files: `tensorboard dev upload --name my_exp --logdir path/to/output_dir`, and take the provided URL to the TensorBoard's console.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKh5Q2pZgDN3"
      },
      "source": [
        "**URL :** *EDIT!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSGlnszMgDN3"
      },
      "source": [
        "<a name=\"section-taskA\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Document Classification with PyTorch (25 points)</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJt7mSR9gDN3"
      },
      "source": [
        "The aim of this task is identical to the one of Assignment 2 - Task B, namely to design a document classification model that exploits pre-trained word embeddings. It is of course allowed to use the preprocessed text, the dictionary, or any other relevant code or processings, done in the previous assignments.\n",
        "\n",
        "In this task, you implement a document classification model using PyTorch, which given a document/sentence (consisting of a set of words) predicts the corresponding class. Before getting started with coding, have a look at the <a href=\"#section-tensorboard\">optional task</a>, as you may want to already include `Tensorboard` in the code. The implementation of the classifier should cover the points below.\n",
        "\n",
        "**Preprocessing and dictionary (1 point):** Following previous assignments, load the train, validation, and test datasets, apply necessary preprocessing steps, and create a dictionary of words.\n",
        "\n",
        "**Data batching (4 points):** Using the dictionary, create batches for any given dataset (train/validation/test). Each batch is a two-dimensional matrix of *batch-size* to *max-document-length*, containing the IDs of the words in the corresponding documents. *Batch-size* and *max-document-length* are two hyper-parameters and can be set to any appropriate values (*Batch-size* must be higher than 1 and *max-document-length* at least 50 words). If a document has more than *max-document-length* words, only the first *max-document-length* words should be kept.\n",
        "\n",
        "**Word embedding lookup (2 point):** Using `torch.nn.Embedding`, create a lookup for the embeddings of all the words in the dictionary. The lookup is in fact a matrix, which maps the ID of each word to the corresponding word vector. Similar to Assignment 2, use the pre-trained vectors of a word embedding model (like word2vec or GloVe) to initialize the word embeddings of the lookup. Keep in mind that the embeddings of the words in the lookup should be matched with the correct vector in the pretrained word embedding. If the vector of a word in the lookup does not exist in the pretrained word embeddings, the corresponding vector should be initialized randomly.\n",
        "\n",
        "**Model definition (3 points):** Define the class `ClassificationAverageModel` as a PyTorch model. In the initialization procedure, the model receives the word embedding lookup, and includes it in the model as model's parameters. These embeddings parameters should be trainable, meaning that the word vectors get updated during model training. Feel free to add any other parameters to the model, which might be necessary for accomplishing the functionalities explained in the following.\n",
        "\n",
        "**Forward function (5 points):** The forward function of the model receives a batch of data, and first fetches the corresponding embeddings of the word IDs in the batch using the lookup. Similar to Assignment 2, the embedding of a document is created by calculating the *element-wise mean* of the embeddings of the document's words. Formally, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
        "\n",
        "$$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$$\n",
        "\n",
        "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document. An important point in the implementation of this formula is that the documents in the batch might have different lengths and therefore each document should be divided by its corresponding $|d|$. Finally, this document embedding is utilized to predict the probability of the output classes, done by applying a linear transformation from the embeddings size to the number of classes, followed by Softmax. The linear transformation also belongs to the model's parameters and will be learned in training.\n",
        "\n",
        "**Loss Function and optimization (2 point):** The loss between the predicted and the actual classes is calculated using Negative Log Likelihood or Cross Entropy. Update the model's parameters using any appropriate optimization mechanism such as Adam.\n",
        "\n",
        "**Early Stopping (2 points):** After each epoch, evaluate the model on the *validation set* using accuracy. If the evaluation result (accuracy) improves, save the model as the best performing one so far. If the results are not improving after a certain number of evaluation rounds (set as another hyper-parameter) or if training reaches a certain number of epochs, terminate the training procedure.\n",
        "\n",
        "**Test Set Evaluation (1 point):** After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set.\n",
        "\n",
        "**Reporting (1 point):** During loading and processing the collection, provide sufficient information and examples about the data and the applied processing steps. Report the results of the best performing model on the validation and test set in a table.\n",
        "\n",
        "**Overall functionality of the training procedure (4 point).**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lupBB6PFgDN3",
        "outputId": "fa64e931-4ab5-4ad7-d6be-0a64b70304cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to C:\\Users\\Bashar\n",
            "[nltk_data]     Hanna\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Original vs Cleaned Text (Train Data):\n",
            "                                                text  \\\n",
            "0  In addition to the immediate life-saving inter...   \n",
            "1  There are approximately 2.6 million people cla...   \n",
            "2  While aid imports have held up recently, comme...   \n",
            "3  Heavy rainfalls as well as onrush of water fro...   \n",
            "4  Based on field reports 9 , the main production...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  addition immediate life save intervention   un...  \n",
            "1  approximately <num> million people classify ph...  \n",
            "2  aid import hold recently   commercial food fue...  \n",
            "3  heavy rainfall well onrush water upstream megh...  \n",
            "4  base field report <num>    main production cha...  \n",
            "--------------------------------------------------\n",
            "//////////////////////////////////////////////////\n",
            "Total unique tokens: 22796\n",
            "Vocabulary size after applying frequency threshold: 12072\n",
            "Sample of vocabulary: ['neglect', 'ndoh', 'haut', 'ungrade', 'meaning', 'cure', 'basket', 'signify', 'primary', 'hurriyet']\n",
            "//////////////////////////////////////////////////\n",
            "Processed Validation Data Example:\n",
            "                                        cleaned_text  \\\n",
            "0  veteran throw roadblock main northbound highwa...   \n",
            "1  water department complain lack skilled worker ...   \n",
            "2  <num> <date> <num>   ministry health democrati...   \n",
            "3  kakuma kalobeyei   host refugee community depe...   \n",
            "4  ' raqqa empty civilian take human shield ' say...   \n",
            "5  <num> case malnutrition first <num> week <num>...   \n",
            "6  \" locust kill <num>   agricultural crop idlib ...   \n",
            "7  ground justify adoption principle statement me...   \n",
            "8  \" people force fetch foul water area darsasiya...   \n",
            "9  iranian official say <num> <num> people need e...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  veteran throw roadblock main <OOV> highway mor...  \n",
            "1  water department complain lack skilled worker ...  \n",
            "2  <num> <date> <num> ministry health democratic ...  \n",
            "3  kakuma kalobeyei host refugee community depend...  \n",
            "4  ' raqqa empty civilian take human shield ' say...  \n",
            "5  <num> case malnutrition first <num> week <num>...  \n",
            "6  \" locust kill <num> agricultural crop idlib pr...  \n",
            "7  ground justify adoption principle statement me...  \n",
            "8  \" people force fetch <OOV> water area <OOV> on...  \n",
            "9  iranian official say <num> <num> people need e...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data_path = \"../nlp2023_24_data/\"\n",
        "train_data = pd.read_csv(f\"{data_path}thedeep.subset.train.txt\", sep=\",\", names=[\"sentence_id\", \"text\", \"label\"])\n",
        "validation_data = pd.read_csv(f\"{data_path}thedeep.subset.validation.txt\", sep=\",\", names=[\"sentence_id\", \"text\", \"label\"])\n",
        "test_data = pd.read_csv(f\"{data_path}thedeep.subset.test.txt\", sep=\",\", names=[\"sentence_id\", \"text\", \"label\"])\n",
        "\n",
        "# Download and set up stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Initialize Spacy and Stemmer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def clean_and_normalize_text(text, use_stemming=False, remove_stopwords=True):\n",
        "    \"\"\"\n",
        "    Cleans and normalizes text by lowercasing, removing special characters, and handling tokens like NUMTOKEN and DATETOKEN.\n",
        "    \"\"\"\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Replace numbers and months\n",
        "    text = re.sub(r\"\\b\\d+(\\.\\d+)?(/\\d+)?\\b\", \"NUMTOKEN\", text)  # Replace numbers with NUMTOKEN\n",
        "    text = re.sub(r\"\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\b\", \"DATETOKEN\", text, flags=re.IGNORECASE)\n",
        "    #text = re.sub(r\"\\b(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\b\", \"DATETOKEN\", text, flags=re.IGNORECASE)\n",
        "    text = text.replace(\".\", \" \")  # Remove periods\n",
        "    text = text.replace(\",\", \" \")  # Remove commas\n",
        "    text = text.replace(\"?\", \" \")  # Remove question marks\n",
        "    text = text.replace(\"!\", \" \")  # Remove exclamation marks\n",
        "    text = text.replace(\";\", \" \")  # Remove semicolons\n",
        "    text = text.replace(\":\", \" \")  # Remove colons\n",
        "    text = text.replace(\"(\", \" \")  # Remove parentheses\n",
        "    text = text.replace(\")\", \" \")  # Remove parentheses\n",
        "    text = text.replace(\"%\", \" \")  # Remove percentage signs\n",
        "    text = text.replace(\"$\", \" \")  # Remove dollar signs\n",
        "    text = text.replace(\"#\", \" \")  # Remove hashtags\n",
        "    text = text.replace(\"&\", \" \")  # Remove ampersands\n",
        "    text = text.replace(\"-\", \" \")  # Remove hyphens\n",
        "    text = text.replace(\"+\", \" \")  # Remove plus signs\n",
        "    text = text.replace(\"~\", \" \")  # Remove tildes\n",
        "    # Tokenize using Spacy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        # Skip stopwords if remove_stopwords is True\n",
        "        if remove_stopwords and token.text in stop_words:\n",
        "            continue\n",
        "        # Preserve NUMTOKEN and DATETOKEN, otherwise stem/lemmatize\n",
        "        if token.text in [\"NUMTOKEN\", \"DATETOKEN\"]:\n",
        "            tokens.append(token.text)\n",
        "        elif use_stemming:\n",
        "            tokens.append(stemmer.stem(token.text))\n",
        "        else:\n",
        "            tokens.append(token.lemma_)  # Use lemmatization\n",
        "\n",
        "    # Join tokens and replace back special tokens\n",
        "    cleaned_text = \" \".join(tokens).replace(\"NUMTOKEN\", \"<num>\").replace(\"DATETOKEN\", \"<date>\")\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply cleaning to datasets\n",
        "train_data['cleaned_text'] = train_data['text'].apply(clean_and_normalize_text)\n",
        "validation_data['cleaned_text'] = validation_data['text'].apply(clean_and_normalize_text)\n",
        "test_data['cleaned_text'] = test_data['text'].apply(clean_and_normalize_text)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Original vs Cleaned Text (Train Data):\")\n",
        "print(train_data[['text', 'cleaned_text']].head())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "def build_vocabulary(data, min_frequency=2):\n",
        "    \"\"\"\n",
        "    Builds a vocabulary from the cleaned text based on token frequency.\n",
        "    \"\"\"\n",
        "    # Tokenize all the cleaned text and count the frequencies\n",
        "    all_tokens = \" \".join(data['cleaned_text']).split()\n",
        "    token_counts = Counter(all_tokens)\n",
        "\n",
        "    # Apply frequency threshold\n",
        "    vocabulary = {token for token, count in token_counts.items() if count >= min_frequency}\n",
        "\n",
        "    # Add a special token for OOV words\n",
        "    vocabulary.add(\"<OOV>\")\n",
        "\n",
        "    return vocabulary, token_counts\n",
        "\n",
        "# Build vocabulary from training data\n",
        "vocabulary, token_counts = build_vocabulary(train_data, min_frequency=2)\n",
        "\n",
        "print(\"/\" * 50)\n",
        "print(f\"Total unique tokens: {len(token_counts)}\")\n",
        "print(f\"Vocabulary size after applying frequency threshold: {len(vocabulary)}\")\n",
        "print(\"Sample of vocabulary:\", list(vocabulary)[:10])\n",
        "print(\"/\" * 50)\n",
        "\n",
        "def replace_oov_tokens(text, vocabulary):\n",
        "    \"\"\"\n",
        "    Replaces words that are not in the vocabulary with the <OOV> token.\n",
        "    \"\"\"\n",
        "    tokens = text.split()\n",
        "    tokens = [token if token in vocabulary else \"<OOV>\" for token in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Replace OOV tokens in validation and test data\n",
        "train_data['processed_text'] = train_data['cleaned_text']\n",
        "validation_data['processed_text'] = validation_data['cleaned_text'].apply(lambda x: replace_oov_tokens(x, vocabulary))\n",
        "test_data['processed_text'] = test_data['cleaned_text'].apply(lambda x: replace_oov_tokens(x, vocabulary))\n",
        "\n",
        "print(\"Processed Validation Data Example:\")\n",
        "print(validation_data[['cleaned_text', 'processed_text']].head(10))\n",
        "\n",
        "# Optional: Save the vocabulary for reuse\n",
        "import json\n",
        "with open(\"vocabulary.json\", \"w\") as vocab_file:\n",
        "    json.dump(list(vocabulary), vocab_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D-88KjfugDN4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_batches(data, vocabulary, batch_size, max_document_length):\n",
        "    word_to_id = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "    oov_id = word_to_id.get(\"<OOV>\", len(word_to_id))  # Use a new ID if <OOV> is missing\n",
        "\n",
        "    # Tokenize documents into word IDs\n",
        "    def tokenize_to_ids(text):\n",
        "        tokens = text.split()\n",
        "        ids = [word_to_id.get(token, oov_id) for token in tokens]\n",
        "        return ids[:max_document_length]  # Truncate to max_document_length\n",
        "\n",
        "    tokenized_data = data['processed_text'].apply(tokenize_to_ids).tolist()\n",
        "\n",
        "\n",
        "    padded_data = [\n",
        "        seq + [0] * (max_document_length - len(seq)) if len(seq) < max_document_length else seq\n",
        "        for seq in tokenized_data\n",
        "    ]\n",
        "\n",
        "\n",
        "    num_batches = len(padded_data) // batch_size\n",
        "    batches = []\n",
        "    for i in range(num_batches):\n",
        "        batch = padded_data[i * batch_size : (i + 1) * batch_size]\n",
        "        batches.append(np.array(batch))\n",
        "\n",
        "    remainder = len(padded_data) % batch_size\n",
        "    if remainder > 0:\n",
        "        last_batch = padded_data[-remainder:]\n",
        "        last_batch += [[0] * max_document_length] * (batch_size - remainder)  # Pad to batch_size\n",
        "        batches.append(np.array(last_batch))\n",
        "\n",
        "    return np.array(batches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cyhJpeoqnV-T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, vocabulary, max_document_length):\n",
        "        self.word_to_id = {word: idx + 1 for idx, word in enumerate(vocabulary)}\n",
        "        self.oov_id = self.word_to_id.get(\"<OOV>\", len(self.word_to_id))  # Use a new ID if <OOV> is missing\n",
        "        self.max_document_length = max_document_length\n",
        "\n",
        "        # Tokenize, pad data, and store labels\n",
        "        self.data = self._process_data(data)\n",
        "        self.labels = data['label'].tolist()  # Convert labels to a list\n",
        "\n",
        "    def _process_data(self, data):\n",
        "        def tokenize_to_ids(text):\n",
        "            tokens = text.split()\n",
        "            ids = [self.word_to_id.get(token, self.oov_id) for token in tokens]\n",
        "            return ids[:self.max_document_length]  # Truncate to max_document_length\n",
        "\n",
        "        tokenized_data = data['processed_text'].apply(tokenize_to_ids).tolist()\n",
        "        padded_data = [\n",
        "            seq + [0] * (self.max_document_length - len(seq)) if len(seq) < self.max_document_length else seq\n",
        "            for seq in tokenized_data\n",
        "        ]\n",
        "        return padded_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        id_tensor = torch.tensor(self.data[idx], dtype=torch.long)\n",
        "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        mask_tensor = (id_tensor != 0).long()\n",
        "        return id_tensor, mask_tensor, label_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_6y_KdxgDN5",
        "outputId": "1fb5d956-456d-4a49-bd74-1a095b91ec1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized 8409 words with pre-trained embeddings.\n",
            "Randomly initialized 3664 OOV words.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from gensim.downloader import load\n",
        "\n",
        "word2vec = load('word2vec-google-news-300')\n",
        "\n",
        "def create_embedding_layer_with_word2vec(vocabulary, word2vec_model, embedding_dim=300, random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    torch.manual_seed(random_seed)\n",
        "\n",
        "    # Create an embedding matrix\n",
        "    vocab_size = len(vocabulary) + 1\n",
        "    embedding_matrix = np.random.uniform(-0.05, 0.05, (vocab_size, embedding_dim))  # Random init for OOV words\n",
        "    oov_count = 0\n",
        "\n",
        "    for idx, word in enumerate(vocabulary):\n",
        "        if word in word2vec_model:\n",
        "            embedding_matrix[idx+1] = word2vec_model[word]  # Fetch embedding from word2vec\n",
        "        else:\n",
        "            oov_count += 1  # Count OOV words\n",
        "\n",
        "    print(f\"Initialized {vocab_size - oov_count} words with pre-trained embeddings.\")\n",
        "    print(f\"Randomly initialized {oov_count} OOV words.\")\n",
        "\n",
        "    # Convert embedding matrix to a PyTorch tensor\n",
        "    embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
        "\n",
        "    # Create the embedding layer\n",
        "    embedding_layer = torch.nn.Embedding.from_pretrained(embedding_matrix, freeze=False)  # Set freeze=True to keep embeddings fixed\n",
        "\n",
        "    return embedding_layer\n",
        "embedding_layer = create_embedding_layer_with_word2vec(vocabulary, word2vec, embedding_dim=300)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5oHl46C_JQH",
        "outputId": "13428274-968d-4a53-f004-bea48df379e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 300])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(np.array([[90,3123,122,2323],[90,3123,122,2323],[90,3123,122,2323]]))\n",
        "embedding_layer(torch.tensor(np.array([[90,3123,122,2323],[90,3123,122,2323],[90,3123,122,2323]])).to(device)).mean(dim=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oQMKkw_pgDN5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ClassificationAverageModel(nn.Module):\n",
        "    def __init__(self, embedding_layer, num_classes, embedding_dim):\n",
        "        super(ClassificationAverageModel, self).__init__()\n",
        "        # Embedding layer\n",
        "        self.embedding = embedding_layer\n",
        "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, mask):\n",
        "        embeddings = self.embedding(input_ids)  # (batch_size, seq_len, embedding_dim)\n",
        "        masked_embeddings = embeddings * mask.unsqueeze(-1)  # Apply mask\n",
        "        lengths = mask.sum(dim=1, keepdim=True)  # Count valid tokens\n",
        "        docs_mean = masked_embeddings.sum(dim=1) / lengths.clamp(min=1)  # Mean over valid tokens\n",
        "        logits = self.fc(docs_mean)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "sd5QmdKugDN5",
        "outputId": "ee42026a-bcea-4ea9-abf2-074f5babe2af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "--------------------------------------------------\n",
            "| Batch   100 | Loss: 2.4792 | Time/Batch: 29.00 ms |\n",
            "| Batch   200 | Loss: 2.3690 | Time/Batch: 28.03 ms |\n",
            "| Batch   300 | Loss: 2.2702 | Time/Batch: 28.33 ms |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| End of Epoch   1 | Validation Accuracy: 0.5239 |\n",
            "--------------------------------------------------\n",
            "New best model saved with accuracy: 0.5239\n",
            "Epoch 2/3\n",
            "--------------------------------------------------\n",
            "| Batch   100 | Loss: 2.1522 | Time/Batch: 28.69 ms |\n",
            "| Batch   200 | Loss: 2.0486 | Time/Batch: 28.62 ms |\n",
            "| Batch   300 | Loss: 1.9964 | Time/Batch: 27.70 ms |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| End of Epoch   2 | Validation Accuracy: 0.5254 |\n",
            "--------------------------------------------------\n",
            "New best model saved with accuracy: 0.5254\n",
            "Epoch 3/3\n",
            "--------------------------------------------------\n",
            "| Batch   100 | Loss: 1.9060 | Time/Batch: 28.79 ms |\n",
            "| Batch   200 | Loss: 1.8387 | Time/Batch: 28.16 ms |\n",
            "| Batch   300 | Loss: 1.7692 | Time/Batch: 28.43 ms |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| End of Epoch   3 | Validation Accuracy: 0.5508 |\n",
            "--------------------------------------------------\n",
            "New best model saved with accuracy: 0.5508\n",
            "Training complete.\n",
            "Test Accuracy: 0.5607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "import torch.nn as nn\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 3            # Number of epochs\n",
        "LEARNING_RATE = 0.0001  # Learning rate\n",
        "WEIGHT_DECAY = 1.2e-6 # Weight decay\n",
        "CLIP = 0.25           # Gradient clipping (set None to disable)\n",
        "LOG_INTERVAL = 100    # Logging interval\n",
        "SAVE_PATH = \"best_ClassificationAverageModel_model.pth\"  # Save path for the best model\n",
        "BATCH_SIZE = 32\n",
        "max_document_length = 300\n",
        "\n",
        "\n",
        "# Create batches from the training data\n",
        "dataset_train = TextDataset(train_data, vocabulary, max_document_length)\n",
        "dataset_val = TextDataset(validation_data, vocabulary, max_document_length)\n",
        "dataset_test = TextDataset(test_data, vocabulary, max_document_length)\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "# Model, Optimizer, and Loss Function\n",
        "model = ClassificationAverageModel(embedding_layer, num_classes=12, embedding_dim=300)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Optimizer and Loss Function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)#, weight_decay=WEIGHT_DECAY)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.to(device)\n",
        "# Training Function\n",
        "def train(dataloader, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        input, mask,labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "        #print(input.shape)\n",
        "        #print(labels.shape)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(input,mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        if CLIP:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Logging\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % LOG_INTERVAL == 0 and batch_idx > 0:\n",
        "            cur_loss = total_loss / LOG_INTERVAL\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"| Batch {batch_idx:5d} | Loss: {cur_loss:.4f} | Time/Batch: {elapsed * 1000 / LOG_INTERVAL:.2f} ms |\")\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate(dataloader, model):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input, mask, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "            logits = model(input, mask)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    accuracy = report[\"accuracy\"]\n",
        "    return accuracy, report\n",
        "\n",
        "# Main Training Loop\n",
        "best_val_accuracy = 0.0\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Train for one epoch\n",
        "    train(dataloader_train, model, optimizer, criterion)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_accuracy, val_report = evaluate(dataloader_val, model)\n",
        "    print(f\"| End of Epoch {epoch:3d} | Validation Accuracy: {val_accuracy:.4f} |\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        if val_accuracy - best_val_accuracy < 0.00001:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"New best model saved with accuracy: {val_accuracy:.4f}\")\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Test Set Evaluation\n",
        "model.load_state_dict(torch.load(SAVE_PATH))\n",
        "test_accuracy, test_report = evaluate(dataloader_test, model)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['precision', 'recall', 'f1-score', 'support'], dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the report dictionary to a DataFrame for visualization\n",
        "df_report = pd.DataFrame(test_report).transpose()\n",
        "\n",
        "# Drop averages\n",
        "class_metrics = df_report.drop(['accuracy', 'macro avg', 'weighted avg'], errors='ignore')\n",
        "print(df_report.columns)\n",
        "plt.figure(figsize=(12, 6))\n",
        "class_metrics[['precision', 'recall', 'f1-score']].plot(kind='bar')\n",
        "plt.title('Validation Set')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Class')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1DOzEH2gDN5"
      },
      "source": [
        "<a name=\"section-taskB\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Document Classification with BERT (15 points)</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXkqf_TpgDN5"
      },
      "source": [
        "This task aims to conduct the same document classification as Task A, but now by utilizing a pre-trained BERT model. Feel free to reuse any code from the previous task. The implementation of the classifier should cover the points below.\n",
        "\n",
        "**Loading BERT model (2 points):** Use the `transformers` library from `huggingface` to load a (small) pre-trained BERT model. Select a BERT model according to your available resources. The available models can be found [here](https://huggingface.co/models) and [here](https://github.com/google-research/bert).\n",
        "\n",
        "**BERT tokenization (3 points):** For training BERT models, we do not need to create a dictionary anymore, as a BERT model already contains an internal subword dictionary. Following the instruction in `transformers`'s documentation, tokenize the data using the BERT model.  \n",
        "\n",
        "**Model definition and forward function (5 points):** Define the class **`ClassificationBERTModel`** as a PyTorch model. In the initialization procedure, the model receives the loaded BERT model and stores it as the model's parameter. The parameters of the BERT model should be trainable. The forward function of the model receives a batch of data, passes this batch to BERT, and achieves the corresponding document embeddings from the output of BERT. Similar to the previous task, the document embeddings are used for classification by linearly transforming document embeddings to the vectors with the number of classes, followed by applying Softmax.\n",
        "\n",
        "**Training and overall functionality (3 points):** Train the model in a similar fashion to the previous task, namely with the proper loss function, optimization, and early stoping.\n",
        "\n",
        "**Test Set Evaluation (1 point):** After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set.\n",
        "\n",
        "**Reporting (1 point):** Report the results of the best performing model on the validation and test set in a table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTViQ4cRgDN5",
        "outputId": "e1b6666c-3904-41d7-984d-08430416a4ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded BERT model on cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Select device (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "bert_model = BertModel.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "print(f\"Loaded BERT model on {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9xG9QPogDN6",
        "outputId": "1c48c81b-28df-40e7-b5a2-38d0e18e8691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization completed.\n"
          ]
        }
      ],
      "source": [
        "def tokenize_data(data, tokenizer, max_length=100):\n",
        "    \"\"\"\n",
        "    Tokenize the input text using the BERT tokenizer.\n",
        "\n",
        "    Args:\n",
        "    - data (pd.Series): The text data to tokenize.\n",
        "    - tokenizer: Hugging Face tokenizer instance.\n",
        "    - max_length (int): Maximum length for the tokenized sequences.\n",
        "\n",
        "    Returns:\n",
        "    - Tokenized input: Dictionary with input_ids, attention_mask, etc.\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        data.tolist(),\n",
        "        padding=\"max_length\",  # Pad sequences to max_length\n",
        "        truncation=True,       # Truncate sequences longer than max_length\n",
        "        max_length=max_length, # Maximum sequence length\n",
        "        return_tensors=\"pt\"    # Return as PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Tokenize train, validation, and test datasets\n",
        "max_length = 100  # Define maximum sequence length\n",
        "x_train = tokenize_data(train_data[\"text\"], tokenizer, max_length)\n",
        "x_val = tokenize_data(validation_data[\"text\"], tokenizer, max_length)\n",
        "x_test = tokenize_data(test_data[\"text\"], tokenizer, max_length)\n",
        "\n",
        "# Extract labels for train, validation, and test\n",
        "y_train = train_data[\"label\"].values\n",
        "y_val = validation_data[\"label\"].values\n",
        "y_test = test_data[\"label\"].values\n",
        "\n",
        "print(\"Tokenization completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okz89fCegDN6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ClassificationBERTModel(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes):\n",
        "        super(ClassificationBERTModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "\n",
        "        logits = self.classifier(pooled_output)\n",
        "        # probabilities = F.softmax(logits, dim=-1)\n",
        "        return logits\n",
        "\n",
        "NUM_CLASSES = train_data[\"label\"].nunique()\n",
        "\n",
        "# Instantiate the model\n",
        "model = ClassificationBERTModel(bert_model, NUM_CLASSES).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu74N8ePgDN6",
        "outputId": "afa785a6-5931-47ed-e322-d435405badf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataLoaders are ready.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "\n",
        "# Define batch size\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Create TensorDatasets\n",
        "dataset_train = TensorDataset(x_train['input_ids'], x_train['attention_mask'], torch.LongTensor(y_train))\n",
        "dataset_val = TensorDataset(x_val['input_ids'], x_val['attention_mask'], torch.LongTensor(y_val))\n",
        "dataset_test = TensorDataset(x_test['input_ids'], x_test['attention_mask'], torch.LongTensor(y_test))\n",
        "\n",
        "# Create DataLoaders\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, drop_last=True)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
        "\n",
        "print(\"DataLoaders are ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6cF6O-fgDN6",
        "outputId": "cfa50f40-ee88-49a9-c9be-4194cbc483e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "--------------------------------------------------\n",
            "| Batch   100 | Loss: 1.5226 | Time/Batch: 73.74 ms |\n",
            "| Batch   200 | Loss: 0.8544 | Time/Batch: 65.66 ms |\n",
            "| Batch   300 | Loss: 0.7107 | Time/Batch: 65.69 ms |\n",
            "| Batch   400 | Loss: 0.7044 | Time/Batch: 65.88 ms |\n",
            "| Batch   500 | Loss: 0.6816 | Time/Batch: 66.29 ms |\n",
            "| Batch   600 | Loss: 0.6209 | Time/Batch: 66.51 ms |\n",
            "| Batch   700 | Loss: 0.6211 | Time/Batch: 66.54 ms |\n",
            "| End of Epoch   1 | Validation Accuracy: 0.8409 |\n",
            "--------------------------------------------------\n",
            "New best model saved with accuracy: 0.8409\n",
            "Epoch 2/3\n",
            "--------------------------------------------------\n",
            "| Batch   100 | Loss: 0.4859 | Time/Batch: 67.61 ms |\n",
            "| Batch   200 | Loss: 0.4875 | Time/Batch: 66.64 ms |\n",
            "| Batch   300 | Loss: 0.4861 | Time/Batch: 66.71 ms |\n",
            "| Batch   400 | Loss: 0.4979 | Time/Batch: 66.68 ms |\n",
            "| Batch   500 | Loss: 0.4464 | Time/Batch: 66.39 ms |\n",
            "| Batch   600 | Loss: 0.5052 | Time/Batch: 66.47 ms |\n",
            "| Batch   700 | Loss: 0.5054 | Time/Batch: 66.37 ms |\n",
            "| End of Epoch   2 | Validation Accuracy: 0.8297 |\n",
            "--------------------------------------------------\n",
            "Epoch 3/3\n",
            "--------------------------------------------------\n",
            "| Batch   100 | Loss: 0.3194 | Time/Batch: 67.43 ms |\n",
            "| Batch   200 | Loss: 0.3419 | Time/Batch: 66.42 ms |\n",
            "| Batch   300 | Loss: 0.3066 | Time/Batch: 66.47 ms |\n",
            "| Batch   400 | Loss: 0.3261 | Time/Batch: 66.45 ms |\n",
            "| Batch   500 | Loss: 0.3674 | Time/Batch: 66.53 ms |\n",
            "| Batch   600 | Loss: 0.3374 | Time/Batch: 66.46 ms |\n",
            "| Batch   700 | Loss: 0.3585 | Time/Batch: 66.50 ms |\n",
            "| End of Epoch   3 | Validation Accuracy: 0.8359 |\n",
            "--------------------------------------------------\n",
            "Training complete.\n",
            "Test Accuracy: 0.8385\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "import torch.nn as nn\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 3            # Number of epochs\n",
        "LEARNING_RATE = 3e-5  # Learning rate\n",
        "WEIGHT_DECAY = 1.2e-6 # Weight decay\n",
        "CLIP = 0.25           # Gradient clipping (set None to disable)\n",
        "LOG_INTERVAL = 100    # Logging interval\n",
        "SAVE_PATH = \"best_bert_model.pth\"  # Save path for the best model\n",
        "\n",
        "# Optimizer and Loss Function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Function\n",
        "def train(dataloader, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        input_ids, attention_mask, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        if CLIP:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Logging\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % LOG_INTERVAL == 0 and batch_idx > 0:\n",
        "            cur_loss = total_loss / LOG_INTERVAL\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"| Batch {batch_idx:5d} | Loss: {cur_loss:.4f} | Time/Batch: {elapsed * 1000 / LOG_INTERVAL:.2f} ms |\")\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate(dataloader, model):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, attention_mask, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    accuracy = report[\"accuracy\"]\n",
        "    return accuracy, report\n",
        "\n",
        "# Main Training Loop\n",
        "best_val_accuracy = 0.0\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Train for one epoch\n",
        "    train(dataloader_train, model, optimizer, criterion)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_accuracy, val_report = evaluate(dataloader_val, model)\n",
        "    print(f\"| End of Epoch {epoch:3d} | Validation Accuracy: {val_accuracy:.4f} |\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"New best model saved with accuracy: {val_accuracy:.4f}\")\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Test Set Evaluation\n",
        "model.load_state_dict(torch.load(SAVE_PATH))\n",
        "test_accuracy, test_report = evaluate(dataloader_test, model)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyEI2WRVgDN6",
        "outputId": "c1e29401-7e5a-45dd-fd06-514409bf104e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Dataset       | Accuracy |\n",
            "|---------------|----------|\n",
            "| Validation    | 0.8359 |\n",
            "| Test          | 0.8385 |\n"
          ]
        }
      ],
      "source": [
        "print(f\"| Dataset       | Accuracy |\\n|---------------|----------|\")\n",
        "print(f\"| Validation    | {val_accuracy:.4f} |\")\n",
        "print(f\"| Test          | {test_accuracy:.4f} |\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNLeMSpWgDN6",
        "outputId": "6c886bab-3756-42bc-c4b4-e60264e3d02c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the report dictionary to a DataFrame for visualization\n",
        "df_report = pd.DataFrame(test_report).transpose()\n",
        "\n",
        "# Drop averages\n",
        "class_metrics = df_report.drop(['accuracy', 'macro avg', 'weighted avg'], errors='ignore')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "class_metrics[['precision', 'recall', 'f1-score']].plot(kind='bar')\n",
        "plt.title('Validation Set')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Class')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38iNVuJugDN7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
